# -*- coding: utf-8 -*-
"""Fixed Preprocessing Utilities

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a0_2hsARrni01BepKbzgo3P8yWBS7_TG
"""

"""Preprocessing utilities for the Career AI project.

This script fixes critical logical flaws from the original version and
introduces a more robust feature engineering pipeline.

Enhancements:
- **Correct Ordinal Encoding**: Uses OrdinalEncoder for performance columns (P1-P8)
  to preserve their inherent order (BEST > GOOD > AVG > POOR).
- **Text Feature Integration**: Adds a pipeline using CountVectorizer to process
  the crucial 'skills' and 'interests' columns, converting them into
  features the model can use.
- **Structural Refactoring**: Separates the logic for fitting preprocessors on a
  training dataset from the logic of transforming new data for prediction.
- **Robust Path & Column Handling**: Retains the robust path resolution and
  column name normalization from the original script.
- **Clear Constants**: Defines column groups and paths as constants for
  better readability and maintenance.
"""

from __future__ import annotations

import os
import re
from typing import Tuple, Dict, Any, List

import joblib
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler

# --- Configuration Constants ---
MODELS_DIR = "models"
DATA_DIR = "data"
DEFAULT_DATASET = "career_dataset.csv"

# Define the explicit order for performance columns
PERFORMANCE_ORDER = ["POOR", "AVG", "GOOD", "BEST"]

# Define feature groups for clarity and reuse
PERFORMANCE_COLS = [f"P{i}" for i in range(1, 9)]
NUMERIC_COLS = [
    "Linguistic", "Musical", "Bodily", "Logical - Mathematical",
    "Spatial-Visualization", "Interpersonal", "Intrapersonal", "Naturalist"
]
# All other non-performance categorical columns
NOMINAL_COLS = ["Course", "s/p"]
TEXT_COLS = ["skills", "interests"] # These are expected in the input now

# --- Path Resolution Utility ---

def _resolve_path(relative_path: str) -> str:
    """Resolve a project-relative path from either repo root or src/ execution."""
    if os.path.exists(relative_path):
        return relative_path
    here = os.path.dirname(os.path.abspath(__file__))
    candidate = os.path.normpath(os.path.join(here, "..", relative_path))
    if os.path.exists(candidate):
        return candidate
    # Fallback for cases where script is in root and data/models are dirs
    if os.path.basename(candidate) in [DATA_DIR, MODELS_DIR] and not os.path.exists(candidate):
         os.makedirs(candidate, exist_ok=True)
         return candidate
    return relative_path # Return original if resolution fails, allowing for FileNotFoundError


# --- Core Preprocessing Functions ---

def _normalize_and_clean_df(df: pd.DataFrame) -> pd.DataFrame:
    """Normalizes column names and cleans data within a DataFrame."""
    # Column name normalization
    df.columns = [re.sub(r'[^A-Za-z0-9_]+', '', c).lower() for c in df.columns]

    # Standardize key column names that might have variations
    rename_map = {
        'jobprofession': 'job_profession',
        'logicalmathematical': 'logical_mathematical',
        'spatialvisualization': 'spatial_visualization'
    }
    df = df.rename(columns=rename_map)

    # Clean/strip whitespace in string columns
    for c in df.select_dtypes(include=["object"]).columns:
        df[c] = df[c].astype(str).str.strip().fillna("Unknown")

    # Fill missing values for key features
    if 'course' in df.columns:
        df['course'] = df['course'].fillna("Unknown")
    for p_col in PERFORMANCE_COLS:
        if p_col.lower() in df.columns:
            df[p_col.lower()] = df[p_col.lower()].replace('nan', "AVG").fillna("AVG")

    # Handle potential numeric conversion errors
    for num_col in NUMERIC_COLS:
        col_name = re.sub(r'[^A-Za-z0-9_]+', '', num_col).lower()
        if col_name in df.columns:
            df[col_name] = pd.to_numeric(df[col_name], errors='coerce').fillna(df[col_name].median())

    return df


def fit_and_save_preprocessors(file_path: str | None = None) -> None:
    """
    Loads training data, fits the preprocessor and label encoder,
    and saves them to the 'models' directory. This function should be
    run once as part of the model training pipeline.
    """
    if file_path is None:
        file_path = _resolve_path(os.path.join(DATA_DIR, DEFAULT_DATASET))

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Training dataset not found at resolved path: {file_path}")

    df = pd.read_csv(file_path)
    df = _normalize_and_clean_df(df)

    target_col = 'job_profession'
    if target_col not in df.columns:
        raise KeyError(f"Target column '{target_col}' not found after normalization.")

    # Drop identifiers and separate features (X) from target (y)
    drop_cols = [c for c in ["student", "srno", target_col] if c in df.columns]
    X = df.drop(columns=drop_cols)
    y = df[target_col]

    # --- Combine skills and interests into a single text feature for vectorization ---
    # NOTE: Your CSV must now contain 'skills' and 'interests' columns.
    # If they are in lists/pipes, they need to be converted to space-separated strings.
    for col in TEXT_COLS:
        if col not in X.columns:
             X[col] = "" # Add empty column if missing to prevent errors
    X['combined_text'] = X[TEXT_COLS].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

    # --- Define the ColumnTransformer with CORRECT Encoders ---

    # Filter columns to only those present in the dataframe
    present_perf_cols = [c.lower() for c in PERFORMANCE_COLS if c.lower() in X.columns]
    present_num_cols = [re.sub(r'[^A-Za-z0-9_]+', '', c).lower() for c in NUMERIC_COLS if re.sub(r'[^A-Za-z0-9_]+', '', c).lower() in X.columns]
    present_nom_cols = [c.lower() for c in NOMINAL_COLS if c.lower() in X.columns]


    preprocessor = ColumnTransformer(
        transformers=[
            ('text', CountVectorizer(stop_words='english', lowercase=True), 'combined_text'),
            ('ordinal', OrdinalEncoder(categories=[PERFORMANCE_ORDER] * len(present_perf_cols)), present_perf_cols),
            ('onehot', OneHotEncoder(handle_unknown='ignore'), present_nom_cols),
            ('numeric', StandardScaler(), present_num_cols)
        ],
        remainder='drop' # Drop any columns not explicitly handled
    )

    # Fit the preprocessor on the feature data
    preprocessor.fit(X)

    # Fit the label encoder on the target data
    le = LabelEncoder()
    le.fit(y)

    # --- Save the FITTED preprocessor and label encoder ---
    models_dir = _resolve_path(MODELS_DIR)
    os.makedirs(models_dir, exist_ok=True)
    joblib.dump(preprocessor, os.path.join(models_dir, "preprocessor.pkl"))
    joblib.dump(le, os.path.join(models_dir, "label_encoder.pkl"))

    print("✅ Preprocessor and Label Encoder have been fitted and saved successfully.")
    print(f"   - Features used: {len(present_perf_cols) + len(present_num_cols) + len(present_nom_cols)} + text features")
    print(f"   - Target classes found: {len(le.classes_)}")


def prepare_input_for_prediction(user_data: Dict[str, Any]) -> pd.DataFrame:
    """
    Takes a dictionary of user data, converts it into a DataFrame,
    and prepares it for the transformation pipeline.
    """
    # Convert input dict to a DataFrame
    df = pd.DataFrame([user_data])

    # Apply the same cleaning and normalization as the training data
    df.columns = [c.lower() for c in df.columns] # Normalize input keys
    rename_map = {
        'logical_mathematical': 'logical_mathematical',
        'spatial_visualization': 'spatial_visualization'
    }
    df = df.rename(columns=rename_map)

    # Ensure skills/interests are strings
    for col in TEXT_COLS:
        if col in df.columns and isinstance(df.at[0, col], list):
            df.at[0, col] = ' '.join(df.at[0, col])
        elif col not in df.columns:
            df[col] = "" # Add empty value if missing

    # Combine text features just like in training
    df['combined_text'] = df[TEXT_COLS].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

    return df


def load_preprocessors() -> Tuple[ColumnTransformer, LabelEncoder]:
    """Load the saved, fitted preprocessor and label encoder."""
    models_dir = _resolve_path(MODELS_DIR)
    try:
        preprocessor = joblib.load(os.path.join(models_dir, "preprocessor.pkl"))
        le = joblib.load(os.path.join(models_dir, "label_encoder.pkl"))
        print("✅ Fitted preprocessors loaded successfully!")
        return preprocessor, le
    except FileNotFoundError as e:
        print(f"❌ Error: Could not load preprocessors. Have you run the fitting script?")
        raise e


# --- Main execution block to run the fitting process ---
if __name__ == "__main__":
    print("--- Running Preprocessor Fitting and Saving ---")
    print("This will process the training dataset and save the fitted encoders.")
    # You might need to adjust the path to your actual dataset.
    # IMPORTANT: Ensure your dataset CSV now contains 'skills' and 'interests' columns.
    try:
        fit_and_save_preprocessors()
    except FileNotFoundError as e:
        print(f"\nError during preprocessing: {e}")
        print("Please ensure 'data/career_dataset.csv' exists or provide a valid path.")
    except KeyError as e:
        print(f"\nError during preprocessing: {e}")
        print("Please check if the required columns are present in your dataset.")